{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3a43d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "496fbe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import joblib\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93fb40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\ryzen\n",
      "[nltk_data]     5\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce2ff146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "df = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c527c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace ham with 0 and spam with 1\n",
    "df = df.replace(['ham', 'spam'], [0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfaddb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6549538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply text preprocessing to the 'v2' column\n",
    "df['v2'] = df['v2'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00c94aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['v2']\n",
    "y = df['v1']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = classifier.predict(X_test_vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d60106f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.76      0.86       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.98      0.88      0.92      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44cdc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline with TF-IDF vectorizer and Multinomial Naive Bayes classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34108c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters to tune\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__alpha': (0.1, 0.5, 1.0)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a11c852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
       "                                       ('clf', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'clf__alpha': (0.1, 0.5, 1.0),\n",
       "                         'tfidf__max_df': (0.25, 0.5, 0.75),\n",
       "                         'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform grid search with cross-validation (5-fold)\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cb0c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__alpha': 0.1, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ca18301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the testing data\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3736305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.88      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e124df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The classification reports indicate the performance of the model before and after hyperparameter tuning using grid search.\n",
    "\n",
    "#Before Hyperparameter Tuning:\n",
    "\n",
    "#Precision for class 0: 0.96\n",
    "#Recall for class 0: 1.00\n",
    "#F1-score for class 0: 0.98\n",
    "#Precision for class 1: 1.00\n",
    "#Recall for class 1: 0.76\n",
    "#F1-score for class 1: 0.86\n",
    "#Accuracy: 0.97\n",
    "#After Hyperparameter Tuning:\n",
    "\n",
    "#Precision for class 0: 0.98\n",
    "#Recall for class 0: 1.00\n",
    "#F1-score for class 0: 0.99\n",
    "#Precision for class 1: 0.99\n",
    "#Recall for class 1: 0.88\n",
    "#F1-score for class 1: 0.93\n",
    "#Accuracy: 0.98\n",
    "#After hyperparameter tuning, there are improvements in precision, \n",
    "#recall, and F1-score for class 1 (spam). The accuracy of the model also increased to 0.98. Overall,\n",
    "#the model performance improved after hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4efcb1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified messages:\n",
      "Message 683: hi im sue 20 years old work lapdancer love sex text live im bedroom text sue 89555 textoperator g2 1da 150ppmsg 18\n",
      "Message 2312: tddnewsletteremc1couk games thedailydraw dear helen dozens free games great prizeswith\n",
      "Message 3979: ringtoneking 84484\n",
      "Message 1268: u get 2 phone wan na chat 2 set meet call 09096102316 u cum 2moro luv jane xx callså£1minmoremobsemspobox45po139wa\n",
      "Message 730: email alertfrom jeri stewartsize 2kbsubject lowcost prescripiton drvgsto listen email call 123\n",
      "Message 2662: hello darling today would love chat dont tell look like sexy\n",
      "Message 4417: get free call\n",
      "Message 4296: thesmszonecom lets send free anonymous masked messagesim sending message theredo see potential abuse\n",
      "Message 1468: hi lucy hubby meetins day fri b alone hotel u fancy cumin pls leave msg 2day 09099726395 lucy x callså£1minmobsmorelkpobox177hp51fl\n",
      "Message 787: ever thought living good life perfect partner txt back name age join mobile community 100psms\n",
      "Message 2351: download many ringtones u like restrictions 1000s 2 choose u even send 2 yr buddys txt sir 80082 å£3\n",
      "Message 4371: ur balance å£600 next question complete landmark big bob b barry c ben text b c 83738 good luck\n",
      "Message 1894: freemsg hey u got 1 videopic fones reply wild txt ill send u pics hurry im bored work xxx 18 150prcvd stop2stop\n",
      "Message 2819: interflora åòits late order interflora flowers christmas call 0800 505060 place order midnight tomorrow\n",
      "Message 693: purchase stuff today mail po box number\n",
      "Message 1892: call 09090900040 listen extreme dirty live chat going office right total privacy one knows sic listening 60p min 247mp 0870753331018\n",
      "Message 4211: missed call alert numbers called left message 07008009200\n",
      "Message 1874: would like see xxx pics hot nearly banned uk\n",
      "Message 2963: ever notice youre driving anyone going slower idiot everyone driving faster maniac\n",
      "Message 4674: hi babe chloe r u smashed saturday night great weekend u missing sp visionsmscom text stop stop 150ptext\n"
     ]
    }
   ],
   "source": [
    "# Misclassified messages\n",
    "misclassified_indices = y_test[y_test != y_pred].index\n",
    "misclassified_messages = X_test[misclassified_indices]\n",
    "print(\"Misclassified messages:\")\n",
    "for i, message in enumerate(misclassified_messages):\n",
    "    print(f\"Message {misclassified_indices[i]}: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c27fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier:\n",
      "[[949  16]\n",
      " [ 31 119]]\n",
      "Accuracy : 0.95785 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       965\n",
      "           1       0.88      0.79      0.84       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.92      0.89      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_vect, y_train)\n",
    "y_pred_dt = dt.predict(X_test_vect)\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(cm)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, dt.predict(X_test_vect)))\n",
    "print(classification_report(y_test, dt.predict(X_test_vect)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "808c14cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier:\n",
      "[[965   0]\n",
      " [ 28 122]]\n",
      "Accuracy : 0.97489 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       1.00      0.81      0.90       150\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.99      0.91      0.94      1115\n",
      "weighted avg       0.98      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate a RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_vect, y_train)\n",
    "y_pred_rf = rf.predict(X_test_vect)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(cm_rf)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, rf.predict(X_test_vect)))\n",
    "print(classification_report(y_test, rf.predict(X_test_vect)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f8a85d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier:\n",
      "[[963   2]\n",
      " [ 51  99]]\n",
      "Accuracy : 0.95247 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate a VotingClassifier using Logistic Regression and SVC\n",
    "classifier1 = LogisticRegression()\n",
    "classifier2 = SVC()\n",
    "ensemble_classifier = VotingClassifier(estimators=[('lr', classifier1), ('svm', classifier2)])\n",
    "ensemble_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_vc = ensemble_classifier.predict(X_test_vect)\n",
    "cm_vc = confusion_matrix(y_test, y_pred_vc)\n",
    "print(\"Voting Classifier:\")\n",
    "print(cm_vc)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, ensemble_classifier.predict(X_test_vect)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00667a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Random Forest Classifier): [0.97421525 0.9764574  0.9708193  0.9640853  0.9708193 ]\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation scores for RandomForestClassifier\n",
    "scores = cross_val_score(rf, X_train_vect, y_train, cv=5)\n",
    "print(\"Cross-validation scores (Random Forest Classifier):\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac234bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Classifier:\n",
      "[[962   3]\n",
      " [ 24 126]]\n",
      "Accuracy : 0.97578 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate an SVC classifier with balanced class weights\n",
    "svc_classifier = SVC(class_weight='balanced')\n",
    "svc_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_svc = svc_classifier.predict(X_test_vect)\n",
    "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"SVC Classifier:\")\n",
    "print(cm_svc)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, svc_classifier.predict(X_test_vect))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0d8c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate the final accuracy of each model, we need to follow these steps:\n",
    "\n",
    "#Train each model on the training data.\n",
    "#Evaluate each model's performance on the testing data.\n",
    "#Calculate the accuracy for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a06e865b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Classifier Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.88      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "Decision Tree Classifier Accuracy: 0.957847533632287\n",
      "RandomForestClassifier Accuracy: 0.9748878923766816\n",
      "VotingClassifier Accuracy: 0.9524663677130045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model performance\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Multinomial Naive Bayes Classifier Report:\\n\", report)\n",
    "\n",
    "# Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=50)\n",
    "dt_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_dt = dt_classifier.predict(X_test_vect)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Classifier Accuracy:\", accuracy_dt)\n",
    "\n",
    "# RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "rf_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_rf = rf_classifier.predict(X_test_vect)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"RandomForestClassifier Accuracy:\", accuracy_rf)\n",
    "\n",
    "# VotingClassifier using Logistic Regression and SVC\n",
    "log_reg_classifier = LogisticRegression()\n",
    "svc_classifier = SVC()\n",
    "voting_classifier = VotingClassifier(estimators=[('lr', log_reg_classifier), ('svm', svc_classifier)])\n",
    "voting_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_voting = voting_classifier.predict(X_test_vect)\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "\n",
    "print(\"VotingClassifier Accuracy:\", accuracy_voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d9b1c68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spam_classifier_model.pk22']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained model\n",
    "joblib.dump(svc_classifier, 'spam_classifier_model.pk22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a8de2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746d300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3734c061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc7aadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369947b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffcb571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdbb85a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3a452e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206291d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47020cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f73b03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e495d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735af42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2835507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05acbde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba420b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"spam.csv\", encoding='latin1')\n",
    "df = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
    "\n",
    "# Replace ham with 0 and spam with 1\n",
    "df = df.replace(['ham', 'spam'], [0, 1])\n",
    "\n",
    "# Define a function for text preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing to the 'v2' column\n",
    "df['v2'] = df['v2'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into features (X) and labels (y)\n",
    "X = df['v2']\n",
    "y = df['v1']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize Multinomial Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train_vect, y_train)\n",
    "\n",
    "# Predict labels for the testing data\n",
    "y_pred = classifier.predict(X_test_vect)\n",
    "\n",
    "# Evaluate the model performance\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# Define a pipeline with TF-IDF vectorizer and Multinomial Naive Bayes classifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "parameters = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__alpha': (0.1, 0.5, 1.0)\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation (5-fold)\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the testing data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Misclassified messages\n",
    "misclassified_indices = y_test[y_test != y_pred].index\n",
    "misclassified_messages = X_test[misclassified_indices]\n",
    "print(\"Misclassified messages:\")\n",
    "for i, message in enumerate(misclassified_messages):\n",
    "    print(f\"Message {misclassified_indices[i]}: {message}\")\n",
    "\n",
    "# Fit and evaluate a Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_vect, y_train)\n",
    "y_pred_dt = dt.predict(X_test_vect)\n",
    "cm = confusion_matrix(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Classifier:\")\n",
    "print(cm)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, dt.predict(X_test_vect)))\n",
    "print(classification_report(y_test, dt.predict(X_test_vect)))\n",
    "\n",
    "# Fit and evaluate a RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train_vect, y_train)\n",
    "y_pred_rf = rf.predict(X_test_vect)\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Random Forest Classifier:\")\n",
    "print(cm_rf)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, rf.predict(X_test_vect)))\n",
    "print(classification_report(y_test, rf.predict(X_test_vect)))\n",
    "\n",
    "# Fit and evaluate a VotingClassifier using Logistic Regression and SVC\n",
    "classifier1 = LogisticRegression()\n",
    "classifier2 = SVC()\n",
    "ensemble_classifier = VotingClassifier(estimators=[('lr', classifier1), ('svm', classifier2)])\n",
    "ensemble_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_vc = ensemble_classifier.predict(X_test_vect)\n",
    "cm_vc = confusion_matrix(y_test, y_pred_vc)\n",
    "print(\"Voting Classifier:\")\n",
    "print(cm_vc)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, ensemble_classifier.predict(X_test_vect)))\n",
    "\n",
    "# Cross-validation scores for RandomForestClassifier\n",
    "scores = cross_val_score(rf, X_train_vect, y_train, cv=5)\n",
    "print(\"Cross-validation scores (Random Forest Classifier):\", scores)\n",
    "\n",
    "# Fit and evaluate an SVC classifier with balanced class weights\n",
    "svc_classifier = SVC(class_weight='balanced')\n",
    "svc_classifier.fit(X_train_vect, y_train)\n",
    "y_pred_svc = svc_classifier.predict(X_test_vect)\n",
    "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "print(\"SVC Classifier:\")\n",
    "print(cm_svc)\n",
    "print(\"Accuracy : %0.5f \\n\\n\" % accuracy_score(y_test, svc_classifier.predict(X_test_vect)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0916f3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2feab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015f347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91abd847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51a4e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883202df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73905ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dbff7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c8ec7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
